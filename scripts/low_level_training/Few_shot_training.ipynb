{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Visualisation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MIy9tL36DS-dgVxzSJG_JZNR9rylL_NW","authorship_tag":"ABX9TyNqINUTt920scatvPf6GlU9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# TPU initialisaton"],"metadata":{"id":"RIAHF7HJDIcc"}},{"cell_type":"code","source":["try:\n","  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu_address) # TPU detection\n","  tf.config.experimental_connect_to_cluster(tpu)\n","  tf.tpu.experimental.initialize_tpu_system(tpu)\n","  strategy = tf.distribute.experimental.TPUStrategy(tpu) \n","  # Going back and forth between TPU and host is expensive.\n","  # Better to run 128 batches on the TPU before reporting back.\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n","  print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n","except ValueError:\n","  print('TPU failed to initialize.')"],"metadata":{"id":"6dog4UVZDIFO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import random"],"metadata":{"id":"JeXR0DzTFSyW","executionInfo":{"status":"ok","timestamp":1639923940696,"user_tz":0,"elapsed":3050,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["AUTO = tf.data.experimental.AUTOTUNE\n","\n","HEIGHT=720\n","WIDTH=1280\n","COLORS=3"],"metadata":{"id":"BhfBUY_nDG7H","executionInfo":{"status":"ok","timestamp":1639923940697,"user_tz":0,"elapsed":7,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Reading dataset from tf records\n","\n","We start with exploring the images, where we see at least one instance of image"],"metadata":{"id":"ZQcJI-I8C8IJ"}},{"cell_type":"code","source":["!cp -r \"/content/drive/MyDrive/deep learning/Object_detection/Coral_Reef/tf_records_data/seen_data\" \"/home/\""],"metadata":{"id":"AxLHQOInC_gH","executionInfo":{"status":"ok","timestamp":1639923995585,"user_tz":0,"elapsed":52342,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["DATA_PATH= '/home/seen_data/seen_data*'\n","BATCH_SIZE = 64\n","\n","VALIDATION_SPLIT = 0.2\n","filenames = tf.io.gfile.glob(DATA_PATH)\n","random.shuffle(filenames)\n","\n","split = int(len(filenames) * VALIDATION_SPLIT)\n","training_filenames = filenames[split:]\n","validation_filenames = filenames[:split]\n","\n","print(f\"Splitting dataset into {len(training_filenames)} training files and {len(validation_filenames)} validation files\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZEY1NoVDFlb","executionInfo":{"status":"ok","timestamp":1639924145410,"user_tz":0,"elapsed":318,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"906bfb80-b559-4b6e-c94f-4adf7357acae"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Splitting dataset into 13 training files and 3 validation files\n"]}]},{"cell_type":"code","source":["feature_description = {\n","    'height': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'width': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'detections_number':tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'image': tf.io.FixedLenFeature([], tf.string),\n","    'path': tf.io.VarLenFeature(tf.string),\n","    'sequence_id':tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'video_id':tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'video_frame':tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'sequence_frame':tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","    'bbox/xmin':tf.io.VarLenFeature(tf.float32),\n","    'bbox/xmax':tf.io.VarLenFeature(tf.float32),\n","    'bbox/ymin':tf.io.VarLenFeature(tf.float32),\n","    'bbox/ymax':tf.io.VarLenFeature(tf.float32),\n","    'class/text': tf.io.VarLenFeature(tf.string),\n","    'class/label': tf.io.VarLenFeature(tf.int64)\n","}"],"metadata":{"id":"x_pLa354DZZE","executionInfo":{"status":"ok","timestamp":1639924013131,"user_tz":0,"elapsed":365,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def read_tfrecord(example,feature_description=feature_description):\n","  # Parse the input `tf.train.Example` proto using the dictionary above.\n","  x = tf.io.parse_single_example(example, feature_description)\n","\n","  image= tf.io.decode_jpeg(x[\"image\"], channels=3)\n","  #image=tf.cast(image,tf.float32)/255.0\n","  x_mins=tf.sparse.to_dense(x['bbox/xmin'])\n","  y_mins=tf.sparse.to_dense(x['bbox/ymin'])\n","  x_maxs=tf.sparse.to_dense(x['bbox/xmax'])\n","  y_maxs=tf.sparse.to_dense(x['bbox/ymax'])\n","  #n_occurances=x['detections_number']\n","  return image,tf.Tensor((x_mins,y_mins,x_maxs,y_maxs),dtype=tf.uint8,value_index=1)"],"metadata":{"id":"Twv2rSA0Db-I","executionInfo":{"status":"ok","timestamp":1639954279341,"user_tz":0,"elapsed":366,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":176,"outputs":[]},{"cell_type":"code","source":["def load_dataset(filenames):\n","  # read from TFRecords. For optimal performance, use \"interleave(tf.data.TFRecordDataset, ...)\"\n","  # to read from multiple TFRecord files at once and set the option experimental_deterministic = False\n","  # to allow order-altering optimizations.\n","\n","  option_no_order = tf.data.Options()\n","  option_no_order.experimental_deterministic = False\n","\n","  dataset = tf.data.Dataset.from_tensor_slices(filenames)\n","  dataset = dataset.with_options(option_no_order)\n","  dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO) # faster\n","  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n","  return dataset\n","\n","def get_batched_dataset(filenames):\n","  dataset = load_dataset(filenames)\n","  dataset = dataset.shuffle(100)\n","  dataset = dataset.batch(BATCH_SIZE, drop_remainder=False) # drop_remainder will be needed on TPU\n","  dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n","  return dataset\n","\n","def get_training_dataset():\n","  dataset = get_batched_dataset(training_filenames)\n","  dataset = strategy.experimental_distribute_dataset(dataset)\n","  return dataset\n","\n","def get_validation_dataset():\n","  dataset = get_batched_dataset(validation_filenames)\n","  dataset = strategy.experimental_distribute_dataset(dataset)\n","  return dataset"],"metadata":{"id":"Ysits8YwDeN3","executionInfo":{"status":"ok","timestamp":1639954280966,"user_tz":0,"elapsed":5,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["dataset = load_dataset(filenames)\n","\n","for i,x in enumerate(load_dataset(filenames)):\n","  print(x[1].shape)\n","  if i==300:\n","    break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"Mv1Gzzgxu2IN","executionInfo":{"status":"error","timestamp":1639954282689,"user_tz":0,"elapsed":1328,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"2d97b9c1-d2cf-42d0-a401-4bb6520703fc"},"execution_count":178,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-178-3e0ba1c939b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-177-3a36ee68e044>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption_no_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_tfrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2010\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m           \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5503\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5505\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5507\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4533\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4534\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m   3244\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3245\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4508\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4509\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4510\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4511\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"<ipython-input-176-5d788ccce304>\", line 12, in read_tfrecord  *\n        return image,tf.Tensor((x_mins,y_mins,x_maxs,y_maxs),dtype=tf.uint8,value_index=1)\n\n    TypeError: op needs to be an Operation: (<tf.Tensor 'SparseToDense:0' shape=(None,) dtype=float32>, <tf.Tensor 'SparseToDense_1:0' shape=(None,) dtype=float32>, <tf.Tensor 'SparseToDense_2:0' shape=(None,) dtype=float32>, <tf.Tensor 'SparseToDense_3:0' shape=(None,) dtype=float32>)\n"]}]},{"cell_type":"code","source":["dataset=dataset.shuffle(100)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n","dataset = dataset.prefetch(AUTO)"],"metadata":{"id":"Vr8VHlpMwC1T","executionInfo":{"status":"ok","timestamp":1639952235836,"user_tz":0,"elapsed":1570,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":149,"outputs":[]},{"cell_type":"code","source":["for x in dataset:\n","  break"],"metadata":{"id":"11azCqKJv7vk","executionInfo":{"status":"ok","timestamp":1639953549534,"user_tz":0,"elapsed":4551,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":154,"outputs":[]},{"cell_type":"code","source":["v=next(iter(get_batched_dataset(filenames)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"Q4K02Bj4un3X","executionInfo":{"status":"error","timestamp":1639951799597,"user_tz":0,"elapsed":904,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"15aa62aa-5399-422f-c8b8-28a0b1848911"},"execution_count":131,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-131-a79d34c2e003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2843\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [2], [batch]: [1] [Op:IteratorGetNext]"]}]},{"cell_type":"markdown","source":["# TPU initializtion"],"metadata":{"id":"ws16_gPec4Xh"}},{"cell_type":"markdown","source":["#Importing object detection API"],"metadata":{"id":"8ec85vHodgUQ"}},{"cell_type":"code","execution_count":22,"metadata":{"id":"12t2ODGbqv9T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639924563365,"user_tz":0,"elapsed":4378,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"1fd84392-177e-48bc-862c-828ef840f654"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 0: cd: /home/barrier_reef: No such file or directory\n","Cloning into 'models'...\n","remote: Enumerating objects: 3203, done.\u001b[K\n","remote: Counting objects: 100% (3203/3203), done.\u001b[K\n","remote: Compressing objects: 100% (2717/2717), done.\u001b[K\n","remote: Total 3203 (delta 847), reused 1354 (delta 442), pack-reused 0\u001b[K\n","Receiving objects: 100% (3203/3203), 33.41 MiB | 25.84 MiB/s, done.\n","Resolving deltas: 100% (847/847), done.\n"]}],"source":["!cd /home/barrier_reef\n","!rm -rf ./models/\n","\n","!git clone --depth 1 https://github.com/tensorflow/models/\n","!cd models/research/ && protoc object_detection/protos/*.proto --python_out=."]},{"cell_type":"code","source":["%%writefile models/research/setup.py\n","\n","import os\n","from setuptools import find_packages\n","from setuptools import setup\n","\n","REQUIRED_PACKAGES = [\n","    'tf-models-official==2.7.0',\n","    'tensorflow_io'\n","]\n","\n","setup(\n","    name='object_detection',\n","    version='0.1',\n","    install_requires=REQUIRED_PACKAGES,\n","    include_package_data=True,\n","    packages=(\n","        [p for p in find_packages() if p.startswith('object_detection')] +\n","        find_packages(where=os.path.join('.', 'slim'))),\n","    package_dir={\n","        'datasets': os.path.join('slim', 'datasets'),\n","        'nets': os.path.join('slim', 'nets'),\n","        'preprocessing': os.path.join('slim', 'preprocessing'),\n","        'deployment': os.path.join('slim', 'deployment'),\n","        'scripts': os.path.join('slim', 'scripts'),\n","    },\n","    description='Tensorflow Object Detection Library',\n","    python_requires='>3.6',\n",")\n"],"metadata":{"id":"n1LyEu27q-6J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639924563368,"user_tz":0,"elapsed":35,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"58b2d522-46f2-46b9-a31e-ce99ddfdda66"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing models/research/setup.py\n"]}]},{"cell_type":"code","source":["!python -m pip install models/research"],"metadata":{"id":"L_6MCHPgrAYN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639924595604,"user_tz":0,"elapsed":32250,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"51b5c0ea-7c8f-4978-970e-2931030ddf96"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting tf-models-official==2.7.0\n","  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 5.2 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n","\u001b[K     |████████████████████████████████| 23.1 MB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (3.2.2)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.12.8)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 7.8 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (4.0.1)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 5.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 36.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.19.5)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 40.2 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.29.24)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.1.5)\n","Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (2.7.0)\n","Collecting tensorflow-text>=2.7.0\n","  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 38.6 MB/s \n","\u001b[?25hCollecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n","\u001b[K     |████████████████████████████████| 47.6 MB 56 kB/s \n","\u001b[?25hRequirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (0.5.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 43.0 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 32.9 MB/s \n","\u001b[?25hCollecting tf-slim>=1.1.0\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 47.1 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0->object-detection==0.1) (2.0.3)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (21.3)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (4.8)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (4.62.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.0.6)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.42.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.22.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (12.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (2.7.0)\n","Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.7.0->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official==2.7.0->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.7.0->object-detection==0.1) (1.3)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official==2.7.0->object-detection==0.1) (2019.12.20)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official==2.7.0->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0->object-detection==0.1) (3.0.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official==2.7.0->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (0.3.4)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (1.4.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (21.2.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0->object-detection==0.1) (5.4.0)\n","Collecting tensorflow-io-gcs-filesystem>=0.21.0\n","  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 52.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: object-detection, py-cpuinfo, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1683093 sha256=8cf39923058638251df6856535b20a5b24d261899a2501eda892560ca1e4470e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7cudxtzy/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=ba552e70216879dddf9beb5ccecc2ee7bb2b478bfa515fd41e777d6027c0b90d\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=e607d5c5ee55ef651a38f9a98317a073f4417bc5614a8454ef85b36f1fb7aad4\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo seqeval\n","Installing collected packages: tensorflow-io-gcs-filesystem, portalocker, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official, tensorflow-io, object-detection\n","  Attempting uninstall: tensorflow-io-gcs-filesystem\n","    Found existing installation: tensorflow-io-gcs-filesystem 0.22.0\n","    Uninstalling tensorflow-io-gcs-filesystem-0.22.0:\n","      Successfully uninstalled tensorflow-io-gcs-filesystem-0.22.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed colorama-0.4.4 object-detection-0.1 opencv-python-headless-4.5.4.60 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-6.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"]}]},{"cell_type":"markdown","source":["# Downloading the model\n","\n","The list of models can be found in https://github.com/tensorflow/models\n","\n","Size of inputs 1536x1536"],"metadata":{"id":"vSv5DGRsH4w1"}},{"cell_type":"code","source":["from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","from object_detection.utils import colab_utils"],"metadata":{"id":"OxeCElmsH3gD","executionInfo":{"status":"ok","timestamp":1639924635589,"user_tz":0,"elapsed":734,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["model_name=\"efficientdet_d7_coco17_tpu-32\""],"metadata":{"id":"loFj9fQDJ_kx","executionInfo":{"status":"ok","timestamp":1639925323315,"user_tz":0,"elapsed":313,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["! echo {model_name}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5u4RZh9_KDo8","executionInfo":{"status":"ok","timestamp":1639925323962,"user_tz":0,"elapsed":343,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"3ba55a52-6d4f-4db3-9bcd-efa5b9de20c2"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["efficientdet_d7_coco17_tpu-32\n"]}]},{"cell_type":"code","source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/{model_name}.tar.gz\n","!tar -xf {model_name}.tar.gz\n","!mv {model_name}/checkpoint models/research/object_detection/test_data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kihRQtLHwoT","executionInfo":{"status":"ok","timestamp":1639925336964,"user_tz":0,"elapsed":12352,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"e3b00a05-4308-4507-92f1-98d5162c9377"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-19 14:48:44--  http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d7_coco17_tpu-32.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.12.128, 2607:f8b0:400c:c08::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.12.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 394474998 (376M) [application/x-tar]\n","Saving to: ‘efficientdet_d7_coco17_tpu-32.tar.gz’\n","\n","efficientdet_d7_coc 100%[===================>] 376.20M   121MB/s    in 3.1s    \n","\n","2021-12-19 14:48:47 (121 MB/s) - ‘efficientdet_d7_coco17_tpu-32.tar.gz’ saved [394474998/394474998]\n","\n"]}]},{"cell_type":"markdown","source":["Configuring the model"],"metadata":{"id":"E9lUdnpnK_zh"}},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","pipeline_config = f'models/research/object_detection/configs/tf2/ssd_efficientdet_d7_1536x1536_coco17_tpu-32.config'\n","checkpoint_path = 'models/research/object_detection/test_data/checkpoint/ckpt-0'\n","\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aEvbZM_RKvEn","executionInfo":{"status":"ok","timestamp":1639926358331,"user_tz":0,"elapsed":343,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"2402f0bc-053d-4c38-9c3d-d81464952685"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'eval_config': metrics_set: \"coco_detection_metrics\"\n"," use_moving_averages: false\n"," batch_size: 1,\n"," 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BEE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n"," },\n"," 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n"," shuffle: false\n"," num_epochs: 1\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BEE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n"," }\n"," ],\n"," 'model': ssd {\n","   num_classes: 90\n","   image_resizer {\n","     keep_aspect_ratio_resizer {\n","       min_dimension: 1536\n","       max_dimension: 1536\n","       pad_to_max_dimension: true\n","     }\n","   }\n","   feature_extractor {\n","     type: \"ssd_efficientnet-b6_bifpn_keras\"\n","     conv_hyperparams {\n","       regularizer {\n","         l2_regularizer {\n","           weight: 3.9999998989515007e-05\n","         }\n","       }\n","       initializer {\n","         truncated_normal_initializer {\n","           mean: 0.0\n","           stddev: 0.029999999329447746\n","         }\n","       }\n","       activation: SWISH\n","       batch_norm {\n","         decay: 0.9900000095367432\n","         scale: true\n","         epsilon: 0.0010000000474974513\n","       }\n","       force_use_bias: true\n","     }\n","     bifpn {\n","       min_level: 3\n","       max_level: 7\n","       num_iterations: 8\n","       num_filters: 384\n","       combine_method: \"sum\"\n","     }\n","   }\n","   box_coder {\n","     faster_rcnn_box_coder {\n","       y_scale: 10.0\n","       x_scale: 10.0\n","       height_scale: 5.0\n","       width_scale: 5.0\n","     }\n","   }\n","   matcher {\n","     argmax_matcher {\n","       matched_threshold: 0.5\n","       unmatched_threshold: 0.5\n","       ignore_thresholds: false\n","       negatives_lower_than_unmatched: true\n","       force_match_for_each_row: true\n","       use_matmul_gather: true\n","     }\n","   }\n","   similarity_calculator {\n","     iou_similarity {\n","     }\n","   }\n","   box_predictor {\n","     weight_shared_convolutional_box_predictor {\n","       conv_hyperparams {\n","         regularizer {\n","           l2_regularizer {\n","             weight: 3.9999998989515007e-05\n","           }\n","         }\n","         initializer {\n","           random_normal_initializer {\n","             mean: 0.0\n","             stddev: 0.009999999776482582\n","           }\n","         }\n","         activation: SWISH\n","         batch_norm {\n","           decay: 0.9900000095367432\n","           scale: true\n","           epsilon: 0.0010000000474974513\n","         }\n","         force_use_bias: true\n","       }\n","       depth: 384\n","       num_layers_before_predictor: 5\n","       kernel_size: 3\n","       class_prediction_bias_init: -4.599999904632568\n","       use_depthwise: true\n","     }\n","   }\n","   anchor_generator {\n","     multiscale_anchor_generator {\n","       min_level: 3\n","       max_level: 7\n","       anchor_scale: 4.0\n","       aspect_ratios: 1.0\n","       aspect_ratios: 2.0\n","       aspect_ratios: 0.5\n","       scales_per_octave: 3\n","     }\n","   }\n","   post_processing {\n","     batch_non_max_suppression {\n","       score_threshold: 9.99999993922529e-09\n","       iou_threshold: 0.5\n","       max_detections_per_class: 100\n","       max_total_detections: 100\n","     }\n","     score_converter: SIGMOID\n","   }\n","   normalize_loss_by_num_matches: true\n","   loss {\n","     localization_loss {\n","       weighted_smooth_l1 {\n","       }\n","     }\n","     classification_loss {\n","       weighted_sigmoid_focal {\n","         gamma: 1.5\n","         alpha: 0.25\n","       }\n","     }\n","     classification_weight: 1.0\n","     localization_weight: 1.0\n","   }\n","   encode_background_as_zeros: true\n","   normalize_loc_loss_by_codesize: true\n","   inplace_batchnorm_update: true\n","   freeze_batchnorm: false\n","   add_background_class: false\n"," },\n"," 'train_config': batch_size: 128\n"," data_augmentation_options {\n","   random_horizontal_flip {\n","   }\n"," }\n"," data_augmentation_options {\n","   random_scale_crop_and_pad_to_square {\n","     output_size: 1536\n","     scale_min: 0.10000000149011612\n","     scale_max: 2.0\n","   }\n"," }\n"," sync_replicas: true\n"," optimizer {\n","   momentum_optimizer {\n","     learning_rate {\n","       cosine_decay_learning_rate {\n","         learning_rate_base: 0.07999999821186066\n","         total_steps: 300000\n","         warmup_learning_rate: 0.0010000000474974513\n","         warmup_steps: 2500\n","       }\n","     }\n","     momentum_optimizer_value: 0.8999999761581421\n","   }\n","   use_moving_average: false\n"," }\n"," fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/ckpt-0\"\n"," num_steps: 300000\n"," startup_delay_steps: 0.0\n"," replicas_to_aggregate: 8\n"," max_number_of_boxes: 100\n"," unpad_groundtruth_tensors: false\n"," fine_tune_checkpoint_type: \"classification\"\n"," use_bfloat16: true\n"," fine_tune_checkpoint_version: V2,\n"," 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n"," tf_record_input_reader {\n","   input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n"," }}"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["# Modifying the configuration of the model\n","\n","model_config.ssd.num_classes = 1\n","model_config.ssd.freeze_batchnorm = True\n","\n","#Building modified model\n","with strategy.scope():\n","  detection_model = model_builder.build(model_config=model_config,\n","                                        is_training=True)\n","\n","#Restoring the weights for detection model\n","\n"],"metadata":{"id":"px1uyxVoOvVP","executionInfo":{"status":"ok","timestamp":1639926655112,"user_tz":0,"elapsed":8188,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["#Restoring the weights for detection model\n","\n","We do not want to use all of the efficient net configuration, as we have only one class, we want to use the feature extraction layer and the bounding box regression prediction layer and do not include the class prediction layer"],"metadata":{"id":"SD_lQZZ_P42X"}},{"cell_type":"code","source":["tmp_box_predictor_checkpoint  = tf.train.Checkpoint(\n","    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n","    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n",")\n","\n","tmp_model_checkpoint = tf.train.Checkpoint(\n","    _feature_extractor=detection_model._feature_extractor,\n","    _box_predictor=tmp_box_predictor_checkpoint \n",")\n","\n","checkpoint = tf.train.Checkpoint(model=tmp_model_checkpoint)\n","checkpoint.restore(checkpoint_path).expect_partial()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWMFzf3lQiw9","executionInfo":{"status":"ok","timestamp":1639927024026,"user_tz":0,"elapsed":27328,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"8e4c8ba1-d6e8-45a2-836c-810cb0b38a73"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4078f1d8d0>"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["#Runnig dummy images to restore weights\n","tmp_image, tmp_shapes =  detection_model.preprocess(tf.zeros([1, 1536, 1536, 3]))\n","tmp_prediction_dict = detection_model.predict(tmp_image, tmp_shapes)\n","tmp_detections = detection_model.postprocess(tmp_prediction_dict, tmp_shapes)\n","\n","print('Weights restored!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZtnqXX2QymA","executionInfo":{"status":"ok","timestamp":1639927050296,"user_tz":0,"elapsed":26279,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"c2fa82f7-05a9-48eb-9b94-c49e53e3d5db"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Weights restored!\n"]}]},{"cell_type":"code","source":["for i,v in enumerate(detection_model.trainable_variables):\n","    print(f\"i: {i} \\t name: {v.name} \\t shape:{v.shape} \\t dtype={v.dtype}\")"],"metadata":{"id":"zETvc714WtOK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_fine_tune = [v for i,v in enumerate(detection_model.trainable_variables)\n","                if v.name.startswith(r'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor') |\n","                   v.name.startswith(r'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor') |\n","                   ((i >6) & (i<45)) ]"],"metadata":{"id":"0RE7NCrIWsPL","executionInfo":{"status":"ok","timestamp":1639929378931,"user_tz":0,"elapsed":348,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["# Provide dataset for training"],"metadata":{"id":"lFyUh-LScQcm"}},{"cell_type":"code","source":["x[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pxb_tixqcziz","executionInfo":{"status":"ok","timestamp":1639946866760,"user_tz":0,"elapsed":234,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"9663d21c-8e3c-43be-ac5b-9a4f30fc4380"},"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([114.], dtype=float32)>,\n"," <tf.Tensor: shape=(1,), dtype=float32, numpy=array([402.], dtype=float32)>,\n"," <tf.Tensor: shape=(1,), dtype=float32, numpy=array([154.], dtype=float32)>,\n"," <tf.Tensor: shape=(1,), dtype=float32, numpy=array([429.], dtype=float32)>)"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["x[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CznIY_ahdXnu","executionInfo":{"status":"ok","timestamp":1639950753998,"user_tz":0,"elapsed":796,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"60c1cab9-33c8-4251-9c84-353a1645b373"},"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(720, 1280, 3), dtype=float32, numpy=\n","array([[[0.        , 0.4745098 , 0.8666667 ],\n","        [0.        , 0.47843137, 0.87058824],\n","        [0.        , 0.47843137, 0.8627451 ],\n","        ...,\n","        [0.02745098, 0.24313726, 0.3254902 ],\n","        [0.01960784, 0.23529412, 0.31764707],\n","        [0.02352941, 0.23921569, 0.32156864]],\n","\n","       [[0.        , 0.4745098 , 0.8666667 ],\n","        [0.        , 0.47843137, 0.87058824],\n","        [0.        , 0.47843137, 0.8627451 ],\n","        ...,\n","        [0.02352941, 0.23921569, 0.32156864],\n","        [0.01960784, 0.23529412, 0.31764707],\n","        [0.02352941, 0.23921569, 0.32156864]],\n","\n","       [[0.        , 0.4745098 , 0.8666667 ],\n","        [0.        , 0.47843137, 0.87058824],\n","        [0.        , 0.47843137, 0.8627451 ],\n","        ...,\n","        [0.02352941, 0.23921569, 0.32156864],\n","        [0.01960784, 0.23529412, 0.31764707],\n","        [0.02352941, 0.23921569, 0.32156864]],\n","\n","       ...,\n","\n","       [[0.20784314, 0.77254903, 0.77254903],\n","        [0.16470589, 0.7372549 , 0.73333335],\n","        [0.1254902 , 0.70980394, 0.7019608 ],\n","        ...,\n","        [0.16078432, 0.53333336, 0.78431374],\n","        [0.23529412, 0.52156866, 0.7921569 ],\n","        [0.21960784, 0.46666667, 0.74509805]],\n","\n","       [[0.14901961, 0.70980394, 0.7019608 ],\n","        [0.07843138, 0.6509804 , 0.6392157 ],\n","        [0.08235294, 0.68235296, 0.6627451 ],\n","        ...,\n","        [0.21960784, 0.4627451 , 0.6862745 ],\n","        [0.20392157, 0.4392157 , 0.6509804 ],\n","        [0.34901962, 0.5764706 , 0.77254903]],\n","\n","       [[0.10588235, 0.654902  , 0.6431373 ],\n","        [0.09803922, 0.6666667 , 0.64705884],\n","        [0.10196079, 0.70980394, 0.6784314 ],\n","        ...,\n","        [0.5137255 , 0.69803923, 0.9019608 ],\n","        [0.30588236, 0.50980395, 0.69411767],\n","        [0.22745098, 0.44313726, 0.6039216 ]]], dtype=float32)>"]},"metadata":{},"execution_count":106}]},{"cell_type":"code","source":["tf.Variable([1,x[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"yJ2fkK3xr0v8","executionInfo":{"status":"error","timestamp":1639951008781,"user_tz":0,"elapsed":612,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"c8b02907-7f10-44dc-f49e-b3c14e905eee"},"execution_count":115,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-115-139e6ac556f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [] != values[1].shape = [720,1280,3] [Op:Pack]"]}]},{"cell_type":"code","source":["x[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQJiXo80rUrW","executionInfo":{"status":"ok","timestamp":1639951189749,"user_tz":0,"elapsed":548,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"9a3f939b-96b8-4e21-f268-37a925fac5d8"},"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(720, 1280, 3), dtype=float32, numpy=\n","array([[[0.07450981, 0.46666667, 0.56078434],\n","        [0.08627451, 0.47843137, 0.5803922 ],\n","        [0.07058824, 0.45882353, 0.57254905],\n","        ...,\n","        [0.        , 0.5568628 , 0.99607843],\n","        [0.        , 0.5568628 , 0.9882353 ],\n","        [0.        , 0.5568628 , 0.9882353 ]],\n","\n","       [[0.08235294, 0.47843137, 0.5882353 ],\n","        [0.09019608, 0.4862745 , 0.6039216 ],\n","        [0.07058824, 0.4745098 , 0.59607846],\n","        ...,\n","        [0.        , 0.5529412 , 0.99215686],\n","        [0.        , 0.5529412 , 0.9843137 ],\n","        [0.        , 0.5529412 , 0.9843137 ]],\n","\n","       [[0.09411765, 0.49411765, 0.6431373 ],\n","        [0.09411765, 0.5019608 , 0.64705884],\n","        [0.09019608, 0.5137255 , 0.6627451 ],\n","        ...,\n","        [0.        , 0.5529412 , 0.99215686],\n","        [0.        , 0.5529412 , 0.9843137 ],\n","        [0.        , 0.5529412 , 0.9843137 ]],\n","\n","       ...,\n","\n","       [[0.8745098 , 0.9647059 , 0.9882353 ],\n","        [0.89411765, 0.9882353 , 0.99607843],\n","        [0.88235295, 1.        , 0.96862745],\n","        ...,\n","        [0.00784314, 0.56078434, 0.6784314 ],\n","        [0.01176471, 0.53333336, 0.654902  ],\n","        [0.01176471, 0.5176471 , 0.6392157 ]],\n","\n","       [[0.8509804 , 0.9882353 , 0.972549  ],\n","        [0.8745098 , 0.99607843, 0.9764706 ],\n","        [0.9098039 , 0.99607843, 0.9843137 ],\n","        ...,\n","        [0.03137255, 0.5803922 , 0.70980394],\n","        [0.04313726, 0.5529412 , 0.6862745 ],\n","        [0.03921569, 0.5372549 , 0.6666667 ]],\n","\n","       [[0.84313726, 1.        , 0.972549  ],\n","        [0.85882354, 0.99607843, 0.972549  ],\n","        [0.9098039 , 0.9882353 , 0.98039216],\n","        ...,\n","        [0.03137255, 0.5803922 , 0.7176471 ],\n","        [0.0627451 , 0.57254905, 0.7137255 ],\n","        [0.09803922, 0.58431375, 0.7254902 ]]], dtype=float32)>"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["get_batched_dataset(training_filenames)"],"metadata":{"id":"0MeyAcSFuCWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Start fine-tuning!', flush=True)\n","\n","for x in get_batched_dataset(training_filenames):\n","  print(j)\n","  break\n","  gt_boxes_list = [[x[1][0][i],x[1][1][i],x[1][2][i],x[1][3][i]] for i in range(len(x[1][0]))]\n","  gt_classes=[1]*len(x[1][0])\n","  \n","  x['image']\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"P5bevfX4cPu5","executionInfo":{"status":"error","timestamp":1639951321827,"user_tz":0,"elapsed":6049,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"2801bf49-7e18-46b6-c6fc-d533d05cb65b"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["Start fine-tuning!\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-123-e9065a1b8a3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start fine-tuning!'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_batched_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2843\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 1. First element had shape [2] and element 1 had shape [1]. [Op:IteratorGetNext]"]}]},{"cell_type":"code","source":["[i for i in range(4)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjS9epZaeDKv","executionInfo":{"status":"ok","timestamp":1639947196413,"user_tz":0,"elapsed":230,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}},"outputId":"97105d16-bbe4-4956-b78b-f4ea1e58ffcc"},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 1, 2, 3]"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["image=tf.image.resize(image,(1536,1536,3))"],"metadata":{"id":"HUXjt84iYppE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9HpGkZ98b66v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step_fn(image_list,\n","                  groundtruth_boxes_list,\n","                  groundtruth_classes_list,\n","                  model,\n","                  optimizer,\n","                  vars_to_fine_tune):\n","    \"\"\"A single training iteration.\n","\n","    Args:\n","      image_list: A list of [1, height, width, 3] Tensor of type tf.float32.\n","        Note that the height and width can vary across images, as they are\n","        reshaped within this function to be 640x640.\n","      groundtruth_boxes_list: A list of Tensors of shape [N_i, 4] with type\n","        tf.float32 representing groundtruth boxes for each image in the batch.\n","      groundtruth_classes_list: A list of Tensors of shape [N_i, num_classes]\n","        with type tf.float32 representing groundtruth boxes for each image in\n","        the batch.\n","\n","    Returns:\n","      A scalar tensor representing the total loss for the input batch.\n","    \"\"\"\n","    tf.keras.backend.set_learning_phase(True)\n","  \n","    shapes = tf.constant(batch_size * [[1530, 1530, 3]], dtype=tf.int32)\n","    model.provide_groundtruth(\n","        groundtruth_boxes_list=groundtruth_boxes_list,\n","        groundtruth_classes_list=groundtruth_classes_list)\n","    \n","    with tf.GradientTape() as tape:\n","    ### START CODE HERE (Replace instances of `None` with your code) ###\n","\n","        # Preprocess the images\n","        \n","        preprocessed_image_tensor  = tf.concat(\n","           [detection_model.preprocess(image_tensor)[0]\n","           for image_tensor in image_list], axis=0)\n","        true_shape_tensor =  shapes\n","\n","        # Make a prediction\n","        prediction_dict = model.predict(preprocessed_image_tensor, true_shape_tensor)\n","\n","        # Calculate the total loss (sum of both losses)  \n","        losses_dict= model.loss(prediction_dict, true_shape_tensor)\n","    \n","        total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n","\n","        # Calculate the gradients\n","        gradients = tape.gradient(total_loss,vars_to_fine_tune)\n","\n","        # Optimize the model's selected variables\n","        vars_to_fine_tune=optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n","\n","        ### END CODE HERE ###\n","        \n","    return total_loss"],"metadata":{"id":"JkHAMlhSaImP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"Uhk2Gc68LMDw"}},{"cell_type":"code","source":["import pandas as pd\n","from pathlib import Path\n","from math import ceil\n","import json"],"metadata":{"id":"5-J1L299rCkO","executionInfo":{"status":"ok","timestamp":1639944870257,"user_tz":0,"elapsed":258,"user":{"displayName":"Romal Kuzmin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16766307156907606576"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import random\n","import zipfile\n","import io\n","import scipy.misc\n","import numpy as np\n","\n","import glob\n","import imageio\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","tf.get_logger().setLevel('ERROR')"],"metadata":{"id":"xZH-PrHUrEV7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","\n","from object_detection.utils import colab_utils"],"metadata":{"id":"7VDPic8grPnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","\n","    Args:\n","    path: a file path.\n","\n","    Returns:\n","    uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    \n","    img_data = tf.io.gfile.GFile(path, 'rb').read()\n","    image = Image.open(BytesIO(img_data))\n","    (im_width, im_height) = image.size\n","    \n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","\n","def draw_image_with_boxes(image_number,test=None):\n","  if test==None:\n","    vid_id,frame_num=train_df.loc[image_number,['video_id','video_frame']].values\n","  else:\n","    vid_id,frame_num=test_df.loc[image_number,['video_id','video_frame']].values\n","\n","  path_to_image=path_to_data/'train_images'/f\"video_{vid_id}\"/f\"{frame_num}.jpg\"\n","\n","  box_dict=train_df.loc[image_number,'annotations']\n","  box_dict=json.loads(box_dict.replace(\"'\", '\"'))\n","  image = Image.open(path_to_image)\n","  \n","  for v in (box_dict):\n","    x_min=v['x']\n","    x_max=v['x']+v['width']\n","    y_min=v['y']\n","    y_max=v['y']+v['height']\n","    \n","    viz_utils.draw_bounding_box_on_image(image,\n","                                        y_min,\n","                                        x_min,\n","                                        y_max,\n","                                        x_max,\n","                                        use_normalized_coordinates=False)\n","  \n","  return image"],"metadata":{"id":"z4t073zurLPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_share=0.25\n","data=pd.read_csv(path_to_data/'train.csv')\n","\n","index_values=data.groupby('video_id').apply(lambda x: max(x.index)).rename('last_index').reset_index()\n","index_values['first_index']=(index_values['last_index']*(1-test_share)+ \\\n","                             index_values['last_index'].shift(1).fillna(0)*test_share).apply(ceil)\n","\n","\n","test_filter=np.zeros(data.shape[0])\n","\n","for _,val in index_values.iterrows():\n","  test_filter[val['first_index']:val['last_index']+1]=1\n","\n","test_df=data[test_filter==1]\n","train_df=data[test_filter!=1]\n","\n","train_df=(train_df[train_df['annotations']!='[]']).reset_index(drop=True)\n","test_df=(test_df[test_df['annotations']!='[]']).reset_index(drop=True)\n","\n","print(f\"Number of items in train dataset {train_df.shape[0]}\")\n","print(f\"Number of items in test dataset {test_df.shape[0]}\")"],"metadata":{"id":"64G5tlC5rW4O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline"],"metadata":{"id":"8JDcFuHKrhKZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_image_with_boxes(1667,test=None)"],"metadata":{"id":"YdeX_qbkri1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_image_with_boxes(210,test=None)"],"metadata":{"id":"UTmwPJ3brjkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["draw_image_with_boxes(1450,test=None)"],"metadata":{"id":"kzRsdEdyrl49"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"1CryFjTWDV6U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"VPQLOPlKDWea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"n6fh-gHEDWmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with strategy.scope():"],"metadata":{"id":"Q7DaBBMgDWu7"},"execution_count":null,"outputs":[]}]}