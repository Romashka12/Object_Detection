{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "MODEL_DIR='../results/models/'\n",
    "MODEL_NAME='Model_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model=tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'MODEL_NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import gc\n",
    "import glob\n",
    "import io\n",
    "import IPython\n",
    "import json\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "INPUT_DIR = '/kaggle/input/tensorflow-great-barrier-reef/'\n",
    "sys.path.insert(0, INPUT_DIR)\n",
    "import greatbarrierreef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "detect_fn_tf_odt = tf.saved_model.load(os.path.join(os.path.join(MODEL_DIR, 'output'), 'saved_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import greatbarrierreef\n",
    "env = greatbarrierreef.make_env()   # initialize the environment\n",
    "iter_test = env.iter_test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_THRESHOLD = 0.3\n",
    "\n",
    "submission_dict = {\n",
    "    'id': [],\n",
    "    'prediction_string': [],\n",
    "}\n",
    "\n",
    "for (image_np, sample_prediction_df) in iter_test:\n",
    "    height, width, _ = image_np.shape\n",
    "    \n",
    "    # Run object detection using the TensorFlow model.\n",
    "    detections = detect(image_np)\n",
    "    \n",
    "    # Parse the detection result and generate a prediction string.\n",
    "    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n",
    "    predictions = []\n",
    "    for index in range(num_detections):\n",
    "        score = detections['detection_scores'][0][index].numpy()\n",
    "        if score < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        bbox = detections['detection_boxes'][0][index].numpy()\n",
    "        y_min = int(bbox[0] * height)\n",
    "        x_min = int(bbox[1] * width)\n",
    "        y_max = int(bbox[2] * height)\n",
    "        x_max = int(bbox[3] * width)\n",
    "        \n",
    "        bbox_width = x_max - x_min\n",
    "        bbox_height = y_max - y_min\n",
    "        \n",
    "        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "    \n",
    "    # Generate the submission data.\n",
    "    prediction_str = ' '.join(predictions)\n",
    "    sample_prediction_df['annotations'] = prediction_str\n",
    "    env.predict(sample_prediction_df)\n",
    "\n",
    "    print('Prediction:', prediction_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {folders[\"CHECKPOINT_PATH\"]}/ckpt-*.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "ckps = glob.glob(folders[\"CHECKPOINT_PATH\"]+\"/ckpt-*.index\")\n",
    "ckps.sort(key=os.path.getmtime)\n",
    "\n",
    "ckp_file = ckps[-1][:-6]\n",
    "print(ckp_file)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(ckp_file).expect_partial()\n",
    "\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_image_pred(df, idx):\n",
    "\n",
    "    image_np = load_image_into_np(df.iloc[idx].image_path)\n",
    "    \n",
    "    height, width, _ = image_np.shape\n",
    "    input_tensor = tf.cast(np.expand_dims(image_np, 0), tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = detections['num_detections'][0].numpy().astype(np.int32) \n",
    "    bboxes = []\n",
    "    scores = []\n",
    "    classes = []\n",
    "    DETECTION_THRESHOLD = 0.15\n",
    "    \n",
    "    for i in range(num_detections):\n",
    "        score = detections['detection_scores'][0][i].numpy()\n",
    "        \n",
    "        if score < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        bboxes.append(list(detections['detection_boxes'][0][i].numpy()))\n",
    "        scores.append(score)\n",
    "        classes.append(1)\n",
    "    img = plot_detections(image_np, np.array(bboxes), np.array(classes), np.array(scores), category_index, unc=True)\n",
    "    return img\n",
    "\n",
    "cnt = 10\n",
    "fig, ax = plt.subplots(cnt, 2, figsize = (20,40))\n",
    "for row in range(cnt):\n",
    "    idx = np.random.randint(0,val_data_df.shape[0])\n",
    "    gt = get_image_with_annotation(val_data_df, idx)\n",
    "    pred = get_image_pred(val_data_df, idx)\n",
    "    \n",
    "    ax[row][0].imshow(gt)\n",
    "    ax[row][0].set_xticks([])\n",
    "    ax[row][0].set_yticks([])\n",
    "    ax[row][0].set_title(f\"GT_{idx}\")\n",
    "    \n",
    "    ax[row][1].imshow(pred)\n",
    "    ax[row][1].set_xticks([])\n",
    "    ax[row][1].set_yticks([])\n",
    "    ax[row][1].set_title(f\"PR_{idx}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = greatbarrierreef.make_env()  \n",
    "iter_test = env.iter_test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTION_THRESHOLD = 0.15\n",
    "\n",
    "for (image_np, df) in iter_test:\n",
    "    height, width, _ = image_np.shape\n",
    "    \n",
    "    input_tensor = tf.cast(np.expand_dims(image_np, 0), tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = detections['num_detections'][0].numpy().astype(np.int32)\n",
    "    predictions = []\n",
    "    \n",
    "    for index in range(num_detections):\n",
    "        score = detections['detection_scores'][0][index].numpy()\n",
    "\n",
    "        if score < DETECTION_THRESHOLD:\n",
    "            continue\n",
    "\n",
    "        bbox = detections['detection_boxes'][0][index].numpy()\n",
    "        y_min = int(bbox[0] * height)\n",
    "        x_min = int(bbox[1] * width)\n",
    "        y_max = int(bbox[2] * height)\n",
    "        x_max = int(bbox[3] * width)\n",
    "\n",
    "        bbox_width = x_max - x_min\n",
    "        bbox_height = y_max - y_min\n",
    "\n",
    "        predictions.append(f'{score:.2f} {x_min} {y_min} {bbox_width} {bbox_height}')\n",
    "        \n",
    "        \n",
    "    prediction_str = ' '.join(predictions)\n",
    "    df['annotations'] = prediction_str\n",
    "    env.predict(df)\n",
    "\n",
    "sub_df = pd.read_csv('submission.csv')\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./api\n",
    "!rm -rf ./data\n",
    "!rm -rf ./pre-trained-models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
